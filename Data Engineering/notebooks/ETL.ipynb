{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook para ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería para manejo y análisis de estructuras de datos\n",
    "import pandas as pd \n",
    "\n",
    "# Módulo para leer y escribir un archivo/ Manipular rutas\n",
    "import os\n",
    "\n",
    "# Módulo para manipular rutas\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACCIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para automatizar extracción de datos en diferentes formatos\n",
    "\n",
    "def extraccion(path):\n",
    "    with open (path): #se cierra automáticamente para que no tenga que recordar usar file.close()\n",
    "        # Para importar archivos csv\n",
    "        if Path(path).suffix == \".csv\": \n",
    "            data = pd.read_csv(path)\n",
    "            print(\"El archivo: \" + path + \" de formato csv fue importado correctamente\")\n",
    "        # Para importar archivos json\n",
    "        elif Path(path).suffix == \".json\": \n",
    "            data = pd.read_json(path)\n",
    "            print(\"El archivo: \" + path + \" de formato json fue importado correctamente\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\".\").resolve() # Es la ruta donde estoy parado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('C:/Users/Usuario/Desktop/Data Engineer/notebooks') # Me normaliza la ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establezco variables de ruta\n",
    "root_dir = Path(\".\").resolve().parent\n",
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la función extraccion, con el path absoluto de cada datasets\n",
    "\n",
    "amazon_original = extraccion(r\"C:\\Users\\Usuario\\Desktop\\Data Engineer\\data\\raw\\amazon_prime_titles.csv\")\n",
    "disney_original  = extraccion(r\"C:\\Users\\Usuario\\Desktop\\Data Engineer\\data\\raw\\disney_plus_titles.csv\")\n",
    "hulu_original  = extraccion(r\"C:\\Users\\Usuario\\Desktop\\Data Engineer\\data\\raw\\hulu_titles.csv\")\n",
    "netflix_original  = extraccion(r\"C:\\Users\\Usuario\\Desktop\\Data Engineer\\data\\raw\\netflix_titles.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizo copia de los dataset para poder conservar los originales\n",
    "\n",
    "amazon = amazon_original.copy()\n",
    "disney = disney_original.copy()\n",
    "hulu = hulu_original.copy() \n",
    "netflix = netflix_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para normalizar cada dataset\n",
    "\n",
    "def normalizar(Dataframe,plataform):\n",
    "    # Reemplazo los valores nulos\n",
    "    Dataframe.fillna(value = \"No data\", inplace = True)\n",
    "    # Elimino duplicados\n",
    "    Dataframe.drop_duplicates(inplace=True)\n",
    "    # Creo columna \"plataform\", sus valores son la plataforma correspondiente\n",
    "    Dataframe[\"plataform\"] = plataform\n",
    "    print(\"El dataset de \"+ plataform + \" fue normalizado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploramos la información de cada dataset, corroboro la existencia de datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hulu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de observar que las columnas de los dataset son datos representativos, analizamos los datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para determinar datos nulos \n",
    "\n",
    "def nulos(Dataframe,plataforma):\n",
    "    print(\"- La cantidad de elementos nulos en \"+ plataforma + \" es: {}\".format(Dataframe.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos la función nulos en cada dataset\n",
    "\n",
    "nulos(amazon,\"amazon\")\n",
    "nulos(disney,\"disney\")\n",
    "nulos(hulu,\"hulu\")\n",
    "nulos(netflix,\"netflix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciamos la función \"normalizar\" en cada datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizar(amazon,\"amazon\")\n",
    "normalizar(disney,\"disney\")\n",
    "normalizar(hulu,\"hulu\")\n",
    "normalizar(netflix,\"netflix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos todos los datasets para poder trabajar luego con el dataset resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([amazon,disney,hulu,netflix])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro las columnas necesarias para realizar las consultas solicitadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.iloc[:,[1,2,4,7,9,10,12]]\n",
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGA DE DATASET RESULTANTE EN PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_name_output = \"result\"\n",
    "final_output = os.path.join(root_dir,\"data\",\"process\",final_name_output)\n",
    "result.to_csv(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSULTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Máxima duración según tipo de film (película/serie), por plataforma y por año: El request debe ser: get_max_duration(año, plataforma, [min o season])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat= result[\"duration\"].str.split(\"\",n=1,expand=True)\n",
    "result[\"duration\"]=cat[0]\n",
    "result[\"time_unit\"]=cat[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = result.query('plataform == \"hulu\" and release_year == 2018 ')\n",
    "prueba[(prueba[\"duration\"].str.contains(\"min\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de películas y series (separado) por plataforma El request debe ser: get_count_plataform(plataforma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_plataform(plataforma):\n",
    "    \n",
    "    df = result.query(\"plataforma == @plataforma\")\n",
    "    count = df.type.value_counts(sort=True)\n",
    "\n",
    "    return plataforma,str(count[0],count[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_count_plataform(\"netflix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de veces que se repite un género y plataforma con mayor frecuencia del mismo. El request debe ser: get_listedin('genero')\n",
    "Como ejemplo de género pueden usar 'comedy', el cuál deberia devolverles un cunt de 2099 para la plataforma de amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listedin(genero):\n",
    "    cantidad= result[(result['listed_in'].str.contains(genero))].groupby(['plataform'])[\"listed_in\"].count().head(1)\n",
    "    cantidad\n",
    "    return cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_listedin(\"Comedy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor que más se repite según plataforma y año. El request debe ser: get_actor(plataforma, año)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(plataforma,anio):\n",
    "    return result.query('plataform == @plataforma and release_year == @anio').groupby(\"cast\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actor(\"netflix\",2018)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c63d8c7d738c2960218a10995aedf0a7f67a49a231e71037adf0440953cdb45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
